<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>News</title>
<meta name="title" content="News">
<meta name="DC.title" lang="en" content="New">
<meta name="description" content="Looking for an instagram email finder by username guide? Learn more here!">
<meta name="keywords" content="Instagram Email Finder by Username,Instagram Email Finder by Username,Instagram Email Finder,Instagram Email Finder Online Free,How To See What Email You Used for Instagram,Instagram Email Finder GitHub,How To Find Someone on Instagram by Email,Email Finder Instagram">
<meta name="robots" content="index, follow">
<meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
<meta name="bingbot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
<link rel="shortcut icon"  href="../img/cblitzlogowhiteletters.jpg"/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Kumbh+Sans:100,200,300,400,500,600,700,800,900&amp;display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style type="text/css">
.xdb72b8b092d818f9aab4cf2c212cfa1f > .vab7c964ef0809bcb05f10bcc431b940e{
font-size: 1.125rem;
font-style: italic;
margin-top: 0;
font-style: normal;
color: #6d767e;
}
.y125cec48084f0c8961bc55b5168e5bf0{
background-color:#ffc107!important;
border-color:#ffc107!important;
color:#000000!important;
}
html{
scroll-behavior: smooth;
}
.xdb72b8b092d818f9aab4cf2c212cfa1f > a:focus, .xdb72b8b092d818f9aab4cf2c212cfa1f > a:hover{
text-decoration: none;
color: #0388a4;
}
.nav-item{
padding-left:8px;
padding-right:8.5px;
padding-top:4.8px;
padding-bottom:5.1px;
}
footer *{
font-size:16px !important;
}
footer{
background:#080808;
color:#ffffff;
}
a:hover{
color:#ffffff;#ffc658!important
}
.post-content *{

font-size: 1.25rem;
}
.xdb72b8b092d818f9aab4cf2c212cfa1f > .vab7c964ef0809bcb05f10bcc431b940e > a{
text-decoration: none;
}
.navbar a{
font-size: 18px!important;
font-weight: bold;
}
footer a{
color:#ffffff;
text-decoration: underline;
}
.xdb72b8b092d818f9aab4cf2c212cfa1f > a > .b10a9591a33d845296f5d233ce62172d3{
font-size: 1.875rem;
margin-top: 1.875rem;
margin-bottom: 0.625rem;
font-weight: 800;
}
.z0b6187d5c1b5185de0c60caf01427b33{
color: #fff;
background-color: #1095b1;
border-color: #0c91ad;
display: inline-block;
font-weight: 800;
line-height: 1.5;
text-align: center;
vertical-align: middle;
cursor: pointer;
padding: 1rem 1.75rem;
font-size: 0.875rem;
border-radius: 0;
transition: color 0.15s ease-in-out, background-color 0.15s ease-in-out, border-color 0.15s ease-in-out, box-shadow 0.15s ease-in-out;
}
*{
font-family: 'Kumbh Sans', sans-serif;
}
ul{
list-style: circle;
}
.f0ffcd21a3ae7b78c2f074f9f5e1d7532:hover{
box-shadow: 0 50px 49.8px -25px rgb(0 0 0 / 30%);
transform: rotate(-2deg) scale(1.03);
}
.zb9668e6453c19564542a685265a63e5c p,.zb9668e6453c19564542a685265a63e5c span,.zb9668e6453c19564542a685265a63e5c label{
font-size:16px!important;
}
.zb9668e6453c19564542a685265a63e5c a{
font-size:16px;
}
.nav-link{
color: #000000;

}
.b7d5ff052240a144e1ff96f7b3ef0b0a6 p,.b7d5ff052240a144e1ff96f7b3ef0b0a6 a,.b7d5ff052240a144e1ff96f7b3ef0b0a6 span,.b7d5ff052240a144e1ff96f7b3ef0b0a6 label{
font-size:16px!important;
}
a{
text-decoration: none!important;
}
.b7d5ff052240a144e1ff96f7b3ef0b0a6 a,.zb9668e6453c19564542a685265a63e5c a{
color:#000000!important;
text-decoration: underline !important;
}
.btn-md{
padding: 14.6px 30.3px;
border-radius: 0;
}
.vab7c964ef0809bcb05f10bcc431b940e a{
color: black;
}
.xdb72b8b092d818f9aab4cf2c212cfa1f > a{
color: #212529;
}
.xdb72b8b092d818f9aab4cf2c212cfa1f > a > .tc7b17c0837fe953558d6e221731d5a3e{
font-weight: 300;
margin-bottom: 0.625rem;
}
.justify-content-evenly{
justify-content: space-evenly;
}
</style>
</head>
<body>
<nav class="navbar-expand-lg navbar">
<a class="navbar-brand" href="../instagram-email-finder-by-username.html"  ><img alt="../img/cblitzlogowhiteletters.jpg" src="../img/cblitzlogowhiteletters.jpg"  width="150px" ></a>
<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
<span class="navbar-toggler-icon"></span></button><div class="navbar-collapse collapse" id="navbarSupportedContent">
<ul class="ml-auto align-items-center navbar-nav d-flex"><li class="nav-item"><a class="yb8a0d8c26f98194f105f45d7160e3335 nav-link" href="../news.html" rel="nofollow" >News</a></li>
<li class="nav-item">
<a class="nav-link yb8a0d8c26f98194f105f45d7160e3335" href="../instagram-email-finder-by-username.html" >Instagram Email Finder by Username</a>
</li>
<li class="nav-item">
<a class="yb8a0d8c26f98194f105f45d7160e3335 nav-link" href="../instagram-email-finder.html" >instagram email finder</a>
</li>
<li class="nav-item">
<a class="yb8a0d8c26f98194f105f45d7160e3335 nav-link" href="../instagram-email-finder-online-free.html" >instagram email finder online free</a>
</li>
<li class="nav-item">
<a class="yb8a0d8c26f98194f105f45d7160e3335 nav-link" href="../how-to-see-what-email-you-used-for-instagram.html" >how to see what email you used for instagram</a>
</li>
<li class="nav-item dropdown">
<a class="yb8a0d8c26f98194f105f45d7160e3335 nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-expanded="false">More</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
<a class="dropdown-item" href="../instagram-email-finder-github.html"  >instagram email finder github</a><a class="dropdown-item" href="../how-to-find-someone-on-instagram-by-email.html"  >how to find someone on instagram by email</a><a class="dropdown-item" href="../email-finder-instagram.html"  >email finder instagram</a></div>
</li>
<li class="nav-item"><a class="nav-link yb8a0d8c26f98194f105f45d7160e3335" rel=nofollow href="../about-us.html">About Us</a>
</li></ul>
</div>
</nav>
<div class="container-fluid bg-image pb-5">
<div class="container pt-5 pb-5">
<div class="row">
<div class="col-lg-12 text-center">
<h1 class="text-white mb-0 "> 
                     The origin and unexpected evolution of the word "mainframe"</h1>
</div>
</div>
</div>
</div>
<div class="container py-5">
<div class="row gx-4 gx-lg-5 justify-content-center">
<div class="col-md-12">
<div class="xdb72b8b092d818f9aab4cf2c212cfa1f">
                 <h1 class="pt-2 text-capitalize"><b>The origin and unexpected evolution of the word "mainframe"</b></h1>
<p class="vab7c964ef0809bcb05f10bcc431b940e">
Posted by   on 2025-02-01</p>
</div>
<div class="py-4">
<p>&quot;</p>

<p class="\&quot;h5" italic="" mt025="" o6="">\n<em>An editorially independent publication supported by the Simons Foundation.</em>\n</p>

<p class="\&quot;h5" italic="" mt025="" o6="">\n<em>Get the latest news delivered to your inbox.</em>\n</p>

<p bold="" class="\&quot;white" h6="" kern--w="" pangram="" uppercase="">Type search term(s)<span class="\&quot;nav-search__title-addon\&quot;"> and press enter</span></p>

<h6 class="\&quot;uppercase" kern="" ml1="" mv0="">Share</h6>

<ul>
	<li class="\&quot;flex" flex-items-center="" mh05="" relative="">\n
	<div class="\&quot;header__hamburger\&quot;">\n<button block="" class="\&quot;hamburger" hamburger--dots="" mha="" relative="" theme__accent="" z10="">\n\n\n\n</button>\n</div>
	\n</li>
</ul>

<ul absolute="" bg-white="" class="\&quot;nav__local__dropdown" fit-b="" fit-r="">
	<li>\n</li>
	<li class="\&quot;__link" flex="" flex-items-center="" flex-justify-start="">\n
	<div class="\&quot;comments-button" flex="" flex-items-center="" h5="" mr05="" theme__accent-hover="">\n<a class="\&quot;flex" flex-items-center="" pangram="">\n<svg 0="" 50="" class="\&quot;o2\&quot;" enable-background="\&quot;new">
	<title></title>
	<path 0="" 0-9.4-7-9.4-15.6s.7="" 15.6-9.4="" 15.6h-2.2l-.9="" 15.6s-.7="" 4.2="" 4.2h31.2c8.6="" 4.2z="" 7="" 9.4="" 9.4-18.8-9.4h9.4c-8.6="" d="\&quot;M9.4"></path></svg> </a>
	<div><a class="\&quot;flex" flex-items-center="" pangram="">\n\n</a></div>
	<a class="\&quot;flex" flex-items-center="" pangram="">\n</a>

	<div class="\&quot;uppercase" h6t="" kern="" ml05="" mv0=""><a class="\&quot;flex" flex-items-center="" pangram="">Comments</a></div>
	<a class="\&quot;flex" flex-items-center="" pangram="">\n</a>\n</div>
	\n</li>
	<li>\n</li>
	<li class="\&quot;__link" flex="" flex-items-center="" flex-justify-start="">\n
	<div class="\&quot;relative\&quot;">\n<button aria-expanded="\&quot;false\&quot;" class="\&quot;bookmark-button" flex="" flex-items-center="" mh05="" theme__accent-hover="">\n<svg 0="" 50="" class="\&quot;icon\&quot;" enable-background="\&quot;new">
	<title></title>
	<path 0h45.8v50l25.5="" 2.1="" 37.5="" 50v0z="" d="\&quot;M2.1"></path></svg></button>
	<div class="\&quot;h6t" kern="" ml1="" mv0="" theme__text="" uppercase=""><button aria-expanded="\&quot;false\&quot;" class="\&quot;bookmark-button" flex="" flex-items-center="" mh05="" theme__accent-hover="">\n Read Later\n</button></div>
	\n\n

	<div -top-10="" class="\&quot;q-tooltip" force-mobile-placement="" hidden="" ml-n16="" w-32="">\n
	<div class="\&quot;q-tooltip-content\&quot;">\n
	<div -bottom-3="" class="\&quot;q-tooltip-arrow">&nbsp;</div>
	\n

	<div class="\&quot;q-tooltip-inner" pl-1="" py-1="">\n
	<div class="\&quot;h6t" kern--w="" mx025="" relative="" uppercase="" z1="">\n<span class="\&quot;small" no-wrap="">Read Later</span>\n</div>
	\n</div>
	\n</div>
	\n</div>
	\n</div>
	\n</li>
	<li>\n</li>
</ul>

<ul>
	<li class="\&quot;__link" flex="" flex-items-center="" flex-justify-start="">\n
	<div class="\&quot;comments-button" flex="" flex-items-center="" h5="" mr05="" theme__accent-hover="">\n<a class="\&quot;flex" flex-items-center="" pangram="">\n<svg 0="" 50="" class="\&quot;o2\&quot;" enable-background="\&quot;new">
	<title></title>
	<path 0="" 0-9.4-7-9.4-15.6s.7="" 15.6-9.4="" 15.6h-2.2l-.9="" 15.6s-.7="" 4.2="" 4.2h31.2c8.6="" 4.2z="" 7="" 9.4="" 9.4-18.8-9.4h9.4c-8.6="" d="\&quot;M9.4"></path></svg> </a>
	<div><a class="\&quot;flex" flex-items-center="" pangram="">\n\n</a></div>
	<a class="\&quot;flex" flex-items-center="" pangram="">\n</a>

	<div class="\&quot;uppercase" h6t="" kern="" ml05="" mv0=""><a class="\&quot;flex" flex-items-center="" pangram="">Comments</a></div>
	<a class="\&quot;flex" flex-items-center="" pangram="">\n</a>\n</div>
	\n</li>
	<li class="\&quot;__link" flex="" flex-items-center="" flex-justify-start="">\n
	<div class="\&quot;relative\&quot;">\n<button aria-expanded="\&quot;false\&quot;" class="\&quot;bookmark-button" flex="" flex-items-center="" mh05="" theme__accent-hover="">\n<svg 0="" 50="" class="\&quot;icon\&quot;" enable-background="\&quot;new">
	<title></title>
	<path 0h45.8v50l25.5="" 2.1="" 37.5="" 50v0z="" d="\&quot;M2.1"></path></svg></button>
	<div class="\&quot;h6t" kern="" ml1="" mv0="" theme__text="" uppercase=""><button aria-expanded="\&quot;false\&quot;" class="\&quot;bookmark-button" flex="" flex-items-center="" mh05="" theme__accent-hover="">\n Read Later\n</button></div>
	\n\n

	<div -top-10="" class="\&quot;q-tooltip" force-mobile-placement="" hidden="" ml-n16="" w-32="">\n
	<div class="\&quot;q-tooltip-content\&quot;">\n
	<div -bottom-3="" class="\&quot;q-tooltip-arrow">&nbsp;</div>
	\n

	<div class="\&quot;q-tooltip-inner" pl-1="" py-1="">\n
	<div class="\&quot;h6t" kern--w="" mx025="" relative="" uppercase="" z1="">\n<span class="\&quot;small" no-wrap="">Read Later</span>\n</div>
	\n</div>
	\n</div>
	\n</div>
	\n</div>
	\n</li>
</ul>

<h1 class="\&quot;post__title__title" mv025="" noe="" theme__text="">Chatbot Software Begins to Face Fundamental Limitations</h1>

<p class="\&quot;h6" mv1="" o6="" pv025=""><em>January 31, 2025</em></p>

<p>Multistep logic problems can confound LLMs.</p>

<p>Kristina Armitage/<em>Quanta Magazine</em></p>

<h2 class="\&quot;screen-reader-text\&quot;">Introduction</h2>

<p class="\&quot;o8" h5="" mb1="" mt05="" theme__text=""><em>Contributing Writer</em></p>

<p class="\&quot;h6" mv1="" o6="" pv025=""><em>January 31, 2025</em></p>

<p>On December 17, 1962,&nbsp; <em>Life International</em> published <a href="\">a logic puzzle</a> consisting of 15 sentences describing five houses on a street. Each sentence was a clue, such as &ldquo;The Englishman lives in the red house&rdquo; or &ldquo;Milk is drunk in the middle house.&rdquo; Each house was a different color, with inhabitants of different nationalities, who owned different pets, and so on. The story&rsquo;s headline asked: &ldquo;Who Owns the Zebra?&rdquo; Problems like this one have proved to be a measure of the abilities &mdash; limitations, actually &mdash; of today&rsquo;s machine learning models.</p>

<p>Also known as Einstein&rsquo;s puzzle or riddle (likely an apocryphal attribution), the problem tests a certain kind of multistep reasoning. <a href="\">Nouha Dziri</a>, a research scientist at the Allen Institute for AI, and her colleagues recently set transformer-based large language models (LLMs), such as ChatGPT, to work on such tasks &mdash; and largely found them wanting. &ldquo;They might not be able to reason beyond what they have seen during the training data for hard tasks,&rdquo; Dziri said. &ldquo;Or at least they do an approximation, and that approximation can be wrong.&rdquo;</p>

<p>Einstein&rsquo;s riddle requires composing a larger solution from solutions to subproblems, which researchers call a compositional task. Dziri&rsquo;s team showed that LLMs that have only been trained to predict the next word in a sequence &mdash; which is most of them &mdash; are <a href="\">fundamentally limited</a> in their ability to solve compositional reasoning tasks. Other researchers have shown that transformers, the neural network architecture used by most LLMs, have hard mathematical bounds when it comes to solving such problems. Scientists have had some successes pushing transformers past these limits, but those increasingly look like short-term fixes. If so, it means there are fundamental computational caps on the abilities of these forms of artificial intelligence &mdash; which may mean it&rsquo;s time to consider other approaches.</p>

<p>&ldquo;The work is really motivated to help the community make this decision about whether transformers are really the architecture we want to embrace for universal learning,&rdquo; said <a href="\">Andrew Wilson</a>, a machine learning expert at New York University who was not involved with this study.</p>

<h2><strong>Success Begets Scrutiny</strong></h2>

<p>Ironically, LLMs have only themselves to blame for this discovery of one of their limits. &ldquo;The reason why we all got curious about whether they do real reasoning is because of their amazing capabilities,&rdquo; Dziri said. They dazzled on tasks involving natural language, despite the seeming simplicity of their training. During the training phase, an LLM is shown a fragment of a sentence with the last word obscured (though technically it isn&rsquo;t always a single word). The model predicts the missing information and then &ldquo;learns&rdquo; from its mistakes.</p>

<p>The largest LLMs &mdash; OpenAI&rsquo;s o1 and GPT-4, Google&rsquo;s Gemini, Anthropic&rsquo;s Claude &mdash; train on almost all the available data on the internet. As a result, the LLMs end up learning the syntax of, and much of the semantic knowledge in, written language. Such &ldquo;pre-trained&rdquo; models can be further trained, or fine-tuned, to complete sophisticated tasks <a href="\">far beyond</a> simple sentence completion, such as summarizing a complex document or generating code to play a computer game. The results were so powerful that the models seemed, at times, <a href="\">capable of reasoning</a>. Yet they also failed in ways both obvious and surprising.</p>

<p>&ldquo;On certain tasks, they perform amazingly well,&rdquo; Dziri said. &ldquo;On others, they&rsquo;re shockingly stupid.&rdquo;</p>

<p>Nouha Dziri and her team helped show the difficulty current AI systems have with certain kinds of reasoning tasks.</p>

<p>Allen Institute for AI</p>

<p>Take basic multiplication. Standard LLMs, such as ChatGPT and GPT-4, fail badly at it. In early 2023 when Dziri&rsquo;s team asked GPT-4 to multiply two three-digit numbers, it initially succeeded only 59% of the time. When it multiplied two four-digit numbers, accuracy fell to just 4%.</p>

<p>The team also tested the LLMs on tasks like Einstein&rsquo;s riddle, where it also had limited success. GPT-4 always got the right answer when the puzzle involved two houses with two attributes per house. But the accuracy fell to 10% when the complexity of the puzzle increased to four houses with four attributes per house. For the original version in <em>Life International</em> &mdash; five houses, each with five attributes &mdash; the success rate was 0%.</p>

<p>Dziri&rsquo;s team thought that maybe the LLMs simply hadn&rsquo;t seen enough examples in their training data, so they fine-tuned GPT-3 on 1.8 million examples of multiplying two numbers. Then, when they showed it new problems, the LLM aced them &mdash; but only if they were sufficiently similar to what it had seen during training. For example, the training data included the multiplication of two three-digit numbers, and of a two-digit number with a four-digit number, but when the model was asked to multiply a four-digit number with a three-digit number, it succeeded only 2% of the time. &ldquo;If they are truly reasoning and understanding certain tasks, they should get the implicit algorithm,&rdquo; Dziri said. That&rsquo;s not what her team saw. &ldquo;That raises a lot of questions about how LLMs perform tasks and whether they&rsquo;re doing true reasoning.&rdquo;</p>

<p>The team observed the same pattern when it came to solving Einstein&rsquo;s riddle: GPT-3 failed when asked to answer bigger versions of the puzzle compared to the ones it was fine-tuned on. &ldquo;It&rsquo;s mimicking something that it has seen, but it doesn&rsquo;t have full understanding of it,&rdquo; Dziri said.</p>

<h2><strong>Hard Limits</strong></h2>

<p>As Dziri and her co-authors were finalizing their results, a different team was taking another approach to understanding why LLMs struggled with compositional tasks. <a href="\">Binghui Peng</a>, at the time a doctoral student at Columbia University, was working with one of his advisers, Christos Papadimitriou, and colleagues to understand why LLMs &ldquo;hallucinate,&rdquo; or generate factually incorrect information. Peng, now a postdoctoral researcher at Stanford University, suspected it was because transformers seem to lack the &ldquo;capability of composition.&rdquo;</p>

<p>To understand why, imagine we feed an LLM two pieces of information: The father of Fr&eacute;d&eacute;ric Chopin was Nicolas Chopin, and Nicolas Chopin was born on April 15, 1771. If we then ask it, &ldquo;What is the birth date of Fr&eacute;d&eacute;ric Chopin&rsquo;s father?&rdquo; the LLM would have to answer by composing, or putting together, the different facts. In effect, it would need to answer the following nested question: &ldquo;What is the birth date of (Who is the father of (Fr&eacute;d&eacute;ric Chopin)?)?&rdquo; If the LLM predicts the wrong words as an answer, it&rsquo;s said to have hallucinated &mdash; in this case, possibly as a result of failing to solve the compositional task.</p>

<p>Peng wanted to test this hunch. His team started by studying the properties of a simple transformer, one with only a single layer, which learns to &ldquo;pay attention&rdquo; to the ordering and position of a sentence&rsquo;s words when trying to predict the next word. (Modern LLMs have scores of such layers.) The team <a href="\">established a link</a> between the complexity of the transformer layer and the &ldquo;domain size,&rdquo; or the number of bits required to represent the questions. By focusing on this simple model, they proved a mathematical bound. &ldquo;If the total number of parameters in this one-layer transformer is less than the size of a domain, then transformers provably cannot solve the compositional task,&rdquo; Peng said. In other words, an LLM with only one transformer layer was clearly and mathematically limited.</p>

<p>While this was a strong theoretical result, its practical implications weren&rsquo;t clear, because modern LLMs are so much more complex. &ldquo;It&rsquo;s not easy to extend our proof,&rdquo; Peng said. So his team used a different approach to study the abilities of more complicated transformers: They turned to computational complexity theory, which studies problems in terms of the resources, such as time and memory, needed to solve them.</p>

<p>Binghui Peng is part of a team that showed transformers, which underlie most large language models, have inherent mathematical limits to their abilities.</p>

<p>Courtesy of Binghui Peng</p>

<p>They ended up using a well-known conjecture to show that the computational power of even multilayer transformers is limited when it comes to solving complicated compositional problems. Then, in December 2024, Peng and colleagues at the University of California, Berkeley <a href="\">posted a proof</a> &mdash; without relying on computational complexity conjectures &mdash; showing that multilayer transformers indeed cannot solve certain complicated compositional tasks. Basically, some compositional problems will always be beyond the ability of transformer-based LLMs.</p>

<p>&ldquo;If your model gets larger, you can solve much harder problems,&rdquo; Peng said. &ldquo;But if, at the same time, you also scale up your problems, it again becomes harder for larger models.&rdquo; This suggests that the transformer architecture has inherent limitations.</p>

<h2><strong>Pushing the Boundaries</strong></h2>

<p>To be clear, this is not the end of LLMs. Wilson of NYU points out that despite such limitations, researchers are beginning to augment transformers to help them better deal with, among other problems, arithmetic. For example, <a href="\">Tom Goldstein</a>, a computer scientist at the University of Maryland, and his colleagues <a href="\">added a twist</a> to how they presented numbers to a transformer that was being trained to add, by embedding extra &ldquo;positional&rdquo; information in each digit. As a result, the model could be trained on 20-digit numbers and still reliably (with 98% accuracy) add 100-digit numbers, whereas a model trained without the extra positional embedding was only about 3% accurate. &ldquo;This suggests that maybe there are some basic interventions that you could do,&rdquo; Wilson said. &ldquo;That could really make a lot of progress on these problems without needing to rethink the whole architecture.&rdquo;</p>

<p>Another way to overcome an LLM&rsquo;s limitations, beyond just increasing the size of the model, is to provide a step-by-step solution of a problem within the prompt, a technique known as <a href="\">chain-of-thought</a> prompting. Empirical studies have shown that this approach can give an LLM such as GPT-4 a newfound ability to solve more varieties of related tasks. It&rsquo;s not exactly clear why, which has led many researchers to study the phenomenon. &ldquo;We were curious about why it&rsquo;s so powerful and why you can do so many things,&rdquo; said <a href="\">Haotian Ye</a>, &nbsp;a doctoral student at Stanford University.</p>

<p>When Ye was still an undergraduate at Peking University, he and his colleagues <a href="\">modeled the behavior of transformers</a> with and without chain-of-thought prompting. Their proof, using another branch of computer science called circuit complexity theory, established how chain-of-thought prompting essentially turns a large problem into a sequence of smaller problems, making it possible for transformers to tackle more complex compositional tasks. &ldquo;That means &hellip; it can solve some problems that lie in a wider or more difficult computational class,&rdquo; Ye said.</p>

<h2 bold="" class="\&quot;mv0" h5="" kern="" uppercase="">Related:</h2>

<ul>
	<li class="\&quot;mv075" flex="">\n
	<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">The Unpredictable Abilities Emerging From Large AI Models</span>\n</a>\n</h3>
	\n</li>
</ul>

<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">The Unpredictable Abilities Emerging From Large AI Models</span>\n</a>\n</h3>

<ul>
	<li class="\&quot;mv075" flex="">\n
	<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">New Theory Suggests Chatbots Can Understand Text</span>\n</a>\n</h3>
	\n</li>
</ul>

<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">New Theory Suggests Chatbots Can Understand Text</span>\n</a>\n</h3>

<ul>
	<li class="\&quot;mv075" flex="">\n
	<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">How Chain-of-Thought Reasoning Helps Neural Networks Compute</span>\n</a>\n</h3>
	\n</li>
</ul>

<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">How Chain-of-Thought Reasoning Helps Neural Networks Compute</span>\n</a>\n</h3>

<ul>
	<li class="\&quot;mv075" flex="">\n
	<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">Will Transformers Take Over Artificial Intelligence?</span>\n</a>\n</h3>
	\n</li>
</ul>

<h3 class="\&quot;h5t" mb025="" medium="" mt0="">\n<a class="\&quot;theme__accent" theme__text-hover="">\n<span .="" class="\&quot;'">Will Transformers Take Over Artificial Intelligence?</span>\n</a>\n</h3>

<p>But, Ye cautions, their result does not imply that real-world models will actually solve such difficult problems, even with chain-of-thought. The work focused on what a model is theoretically capable of; the specifics of how models are trained dictate how they can come to achieve this upper bound.</p>

<p>Ultimately, as impressive as these results are, they don&rsquo;t contradict the findings from Dziri&rsquo;s and Peng&rsquo;s teams. LLMs are fundamentally matching the patterns they&rsquo;ve seen, and their abilities are constrained by mathematical boundaries. Embedding tricks and chain-of-thought prompting simply extends their ability to do more sophisticated pattern matching. The mathematical results imply that you can always find compositional tasks whose complexity lies beyond a given system&rsquo;s abilities. Even some newer &ldquo;state-space models,&rdquo; which have been touted as more powerful alternatives to transformers, <a href="\">show similar limitations</a>.</p>

<p>On the one hand, these results don&rsquo;t change anything for most people using these tools. &ldquo;The general public doesn&rsquo;t care whether it&rsquo;s doing reasoning or not,&rdquo; Dziri said. But for the people who build these models and try to understand their capabilities, it matters. &ldquo;We have to really understand what&rsquo;s going on under the hood,&rdquo; she said. &ldquo;If we crack how they perform a task and how they reason, we can probably fix them. But if we don&rsquo;t know, that&rsquo;s where it&rsquo;s really hard to do anything.&rdquo;</p>

<p class="\&quot;scale5" mb1="" mt025="" o4="">\n<em>Get Quanta Magazine delivered to your inbox</em>\n</p>

<p class="\&quot;o8" h5="" mb1="" mt05="" theme__text=""><em>Contributing Writer</em></p>

<p class="\&quot;h6" mv1="" o6="" pv025=""><em>January 31, 2025</em></p>

<p class="\&quot;scale5" mb1="" mt025="" o4="">\n<em>Get Quanta Magazine delivered to your inbox</em>\n</p>

<p class="\&quot;gray4" mt025="" scale5="">\n<em>Get highlights of the most important news delivered to your email inbox</em>\n</p>

<h2 class="\&quot;post__category__title" mb1="" mv0="">Also in <span class="\&quot;capitalize\&quot;">Computer Science</span></h2>

<h3 class="\&quot;card__title" h2t="" mv0="" noe="" theme__accent-hover="" transition--color="">\n New Book-Sorting Algorithm Almost Reaches Perfection</h3>

<h3 class="\&quot;card__title" h2t="" mv0="" noe="" theme__accent-hover="" transition--color="">\n Can AI Models Show Us How People Learn? Impossible Languages Point a Way.</h3>

<h3 class="\&quot;card__title" h2t="" mv0="" noe="" theme__accent-hover="" transition--color="">\n Why Computer Scientists Consult Oracles</h3>

<h2 align-c="" class="\&quot;h1" mt1="" noe="" pb025="">Comment on this article</h2>

<p class="\&quot;byline\&quot;"><small><em>Quanta Magazine moderates comments to&nbsp;facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.&nbsp;</em></small></p>

<h2 class="\&quot;h6" inline-block="" kern="" mb1="" mv0="" uppercase="" white="">Next article</h2>

<h2 class="\&quot;bold" login-modal__social-title="" mt0="">Use your social network</h2>

<p class="\&quot;theme__accent" color-transition="" hover--black="" inline="" link="" medium="" pangram="" scale5="">\n<span aria-haspopup="\&quot;dialog\&quot;" class="\&quot;no-wrap\&quot;">Forgot your password ?</span>\n<svg class="\&quot;icon" icon="" icon-offset="" ml05=""><path 25l-17.4-8.7v6.5h0v4.4h32.6v6.5="" d="\&quot;M50"></path></svg></p>

<p class="\&quot;italic" gray4="" mt0="">We&rsquo;ll email you instructions to reset your password</p>

<p class="\&quot;italic" gray4="" mt0="">Enter your new password</p>

<p>&quot;</p>
</div>
<div class="d-flex justify-content-evenly mb-4">
<a class="btn z0b6187d5c1b5185de0c60caf01427b33 text-uppercase" href="visualizing-all-books-of-the-world-in-isbn-space.html">Previous</a>
<a class="btn z0b6187d5c1b5185de0c60caf01427b33 text-uppercase" href="avoid-isp-routers-2024.html">Next</a>
</div>
</div>
</div>
</div>
<footer>
<div class="py-4 pt-5 container" >
<div class="row"><div class="col-lg-3"><p><a class="yb8a0d8c26f98194f105f45d7160e3335" href="../sitemap.html" rel="nofollow">Sitemap</a></p>
<p><a class="yb8a0d8c26f98194f105f45d7160e3335" href="../privacy-policy.html" rel="nofollow">Privacy Policy</a></p>
<p><a class="yb8a0d8c26f98194f105f45d7160e3335" href="../about-us.html" rel="nofollow">About Us</a></p>
<div class="col-lg-12">
<img class="img-fluid f0ffcd21a3ae7b78c2f074f9f5e1d7532" src="../img/cblitzlogowhiteletters.jpg" alt="Instagram Email Finder Online Free">
</div>
</p>
</div><div class="col-lg-3">
<div>
<p>Follow us</p>
<a href="https://www.youtube.com/@cblitztools8146" class="youtube d39fc203705715e96c40bb4ac06999366" rel="nofollow"><i class="fa fa-youtube"></i></a>
</div>
</div></div>
</div>
</footer> 
<script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
var dropdowns = document.querySelectorAll('.dropdown-hover');
function showDropdown() {
var dropdownMenu = this.querySelector('.dropdown-menu');
dropdownMenu.style.display = 'block';
}
function hideDropdown() {
var dropdownMenu = this.querySelector('.dropdown-menu');
dropdownMenu.style.display = 'none';
}
function handleClick(event) {
var target = event.target;
window.location.href = target.getAttribute('href');
}
dropdowns.forEach(function(dropdown) {
dropdown.addEventListener('mouseenter', showDropdown);
dropdown.addEventListener('mouseleave', hideDropdown);
var dropdownMenu = dropdown.querySelector('.dropdown-toggle');
dropdownMenu.addEventListener('click', handleClick);
});
});
</script> 
</body>
</html>